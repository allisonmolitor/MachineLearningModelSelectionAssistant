{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from getpass import getpass\n",
        "\n",
        "def wait_for_user():\n",
        "    input(\"\\nPress Enter to continue...\")\n",
        "\n",
        "def suggest_ml_models():\n",
        "    print(\"Welcome to the Machine Learning Algorithm Suggestion Program!\")\n",
        "    print(\"Answer a few questions to find the most suitable ML algorithm for your problem.\")\n",
        "\n",
        "    print(\"\\nWhat is the nature of your problem?\")\n",
        "    print(\"1. Classification\")\n",
        "    print(\"2. Regression\")\n",
        "    print(\"3. Clustering\")\n",
        "    print(\"4. Dimension Analysis\")\n",
        "    problem_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "    if problem_type == '1':\n",
        "        print(\"\\nWhat is the size of your dataset?\")\n",
        "        print(\"1. Small (less than 10,000 samples)\")\n",
        "        print(\"2. Medium (10,000 to 100,000 samples)\")\n",
        "        print(\"3. Large (more than 100,000 samples)\")\n",
        "        dataset_size = input(\"Enter the corresponding number: \")\n",
        "\n",
        "        if dataset_size == '1':\n",
        "            print(\"\\nBased on your problem type (classification) and dataset size (small),\"\n",
        "                  \" the following algorithms are recommended:\")\n",
        "            print(\"- Naive Bayes\")\n",
        "            print(\"- k-Nearest Neighbors (k-NN)\")\n",
        "            print(\"- Decision Trees\")\n",
        "\n",
        "            print(\"\\nWhat is the nature of your features?\")\n",
        "            print(\"1. Categorical\")\n",
        "            print(\"2. Numerical\")\n",
        "            feature_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "            if feature_type == '1':\n",
        "                print(\"\\nThe Naive Bayes algorithm is well-suited for classification problems with categorical features.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Naive Bayes is a probabilistic algorithm that applies Bayes' theorem to calculate the probability\"\n",
        "                      \" of each class label given the input features. It assumes that the features are conditionally\"\n",
        "                      \" independent given the class label. Naive Bayes is simple, efficient, and performs well on\"\n",
        "                      \" small datasets. However, it assumes independence between features, which may not hold true\"\n",
        "                      \" in some cases.\")\n",
        "                wait_for_user()\n",
        "            elif feature_type == '2':\n",
        "                print(\"\\nThe k-Nearest Neighbors algorithm and Decision Trees are well-suited for classification\"\n",
        "                      \" problems with numerical features.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"k-Nearest Neighbors (k-NN) is a non-parametric algorithm that makes predictions based on the\"\n",
        "                      \" majority class of the k nearest neighbors in the feature space. It is versatile, easy to\"\n",
        "                      \" understand, and works well with small datasets. However, it can be sensitive to the choice\"\n",
        "                      \" of k and may suffer from the curse of dimensionality.\")\n",
        "                print(\"\\nDecision Trees are hierarchical models that recursively split the feature space based on\"\n",
        "                      \" feature values to make predictions. They are interpretable, handle both numerical and\"\n",
        "                      \" categorical features, and capture non-linear relationships. However, they may be prone to\"\n",
        "                      \" overfitting and can be sensitive to small changes in the training data.\")\n",
        "                wait_for_user()\n",
        "            else:\n",
        "                print(\"Invalid input!\")\n",
        "                wait_for_user()\n",
        "                return\n",
        "\n",
        "        elif dataset_size == '2':\n",
        "            print(\"\\nBased on your problem type (classification) and dataset size (medium),\"\n",
        "                  \" the following algorithms are recommended:\")\n",
        "            print(\"- Random Forests\")\n",
        "            print(\"- Gradient Boosting Machines (GBM)\")\n",
        "            print(\"- Support Vector Machines (SVM)\")\n",
        "\n",
        "            print(\"\\nWhat is the nature of your features?\")\n",
        "            print(\"1. Categorical\")\n",
        "            print(\"2. Numerical\")\n",
        "            feature_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "            if feature_type == '1':\n",
        "                print(\"\\nThe Random Forests algorithm and Gradient Boosting Machines (GBM) are well-suited for\"\n",
        "                      \" classification problems with categorical features.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Random Forests are ensemble learning models that combine multiple decision trees to make predictions.\"\n",
        "                      \" They are robust, handle high-dimensional data, and provide feature importances, making them suitable\"\n",
        "                      \" for classification tasks with categorical features. Random Forests can handle complex interactions\"\n",
        "                      \" between variables and mitigate overfitting. However, they can be computationally expensive and may\"\n",
        "                      \" not perform well with highly imbalanced datasets.\")\n",
        "                print(\"\\nGradient Boosting Machines (GBM) are also ensemble learning models that sequentially train weak learners\"\n",
        "                      \" to correct the mistakes of previous learners. GBM can handle complex interactions between features and\"\n",
        "                      \" has high predictive power. However, GBM may be prone to overfitting if not properly tuned and can\"\n",
        "                      \" be computationally expensive.\")\n",
        "                wait_for_user()\n",
        "            elif feature_type == '2':\n",
        "                print(\"\\nThe Support Vector Machines (SVM) algorithm is well-suited for classification problems with\"\n",
        "                      \" numerical features.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Support Vector Machines (SVM) are powerful algorithms that find the best hyperplane to separate classes\"\n",
        "                      \" by maximizing the margin. They can handle both linear and non-linear classification tasks and work well\"\n",
        "                      \" with moderate-sized datasets. SVMs can handle high-dimensional data and are effective in capturing\"\n",
        "                      \" complex decision boundaries. However, SVMs can be sensitive to the choice of kernel and parameters,\"\n",
        "                      \" and training time can be long for large datasets.\")\n",
        "                wait_for_user()\n",
        "            else:\n",
        "                print(\"Invalid input!\")\n",
        "                wait_for_user()\n",
        "                return\n",
        "\n",
        "        elif dataset_size == '3':\n",
        "            print(\"\\nBased on your problem type (classification) and dataset size (large),\"\n",
        "                  \" the following algorithms are recommended:\")\n",
        "            print(\"- Deep Learning (e.g., Neural Networks)\")\n",
        "            print(\"- Convolutional Neural Networks (CNN)\")\n",
        "            print(\"- Recurrent Neural Networks (RNN)\")\n",
        "\n",
        "            print(\"\\nAre you working with image or text data?\")\n",
        "            print(\"1. Image data\")\n",
        "            print(\"2. Text data\")\n",
        "            data_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "            if data_type == '1':\n",
        "                print(\"\\nThe Convolutional Neural Networks (CNN) algorithm is well-suited for classification problems\"\n",
        "                      \" with image data.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Convolutional Neural Networks (CNN) are specialized deep learning models designed for image\"\n",
        "                      \" classification. They can capture local patterns in images through convolutional layers and\"\n",
        "                      \" achieve superior performance in computer vision tasks. CNNs can automatically learn hierarchical\"\n",
        "                      \" representations of images, handle spatial invariance, and can be trained end-to-end. However, they\"\n",
        "                      \" require large amounts of labeled training data and can be computationally intensive to train.\")\n",
        "                wait_for_user()\n",
        "            elif data_type == '2':\n",
        "                print(\"\\nThe Recurrent Neural Networks (RNN) algorithm is well-suited for classification problems\"\n",
        "                      \" with text data.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Recurrent Neural Networks (RNN) are suitable for sequential data, such as text or time series.\"\n",
        "                      \" They can capture dependencies between previous inputs and make predictions based on the context.\"\n",
        "                      \" RNNs can handle variable-length inputs and are capable of learning long-term dependencies. However,\"\n",
        "                      \" they can suffer from vanishing or exploding gradients and may have difficulty capturing\"\n",
        "                      \" long-range dependencies.\")\n",
        "                wait_for_user()\n",
        "            else:\n",
        "                print(\"Invalid input!\")\n",
        "                wait_for_user()\n",
        "                return\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input!\")\n",
        "            wait_for_user()\n",
        "            return\n",
        "\n",
        "    elif problem_type == '2':\n",
        "        print(\"\\nWhat is the complexity of your problem?\")\n",
        "        print(\"1. Simple (few features)\")\n",
        "        print(\"2. Moderate (moderate features)\")\n",
        "        print(\"3. Complex (many features)\")\n",
        "        problem_complexity = input(\"Enter the corresponding number: \")\n",
        "\n",
        "        if problem_complexity == '1':\n",
        "            print(\"\\nBased on your problem type (regression) and problem complexity (simple),\"\n",
        "                  \" the following algorithms are recommended:\")\n",
        "            print(\"- Linear Regression\")\n",
        "            print(\"- Ridge Regression\")\n",
        "            print(\"- Lasso Regression\")\n",
        "\n",
        "            print(\"\\nWhat is the nature of your target variable?\")\n",
        "            print(\"1. Continuous\")\n",
        "            print(\"2. Discrete\")\n",
        "            target_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "            if target_type == '1':\n",
        "                print(\"\\nThe Linear Regression, Ridge Regression, and Lasso Regression algorithms are well-suited for\"\n",
        "                      \" regression problems with continuous target variables.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Linear Regression models estimate the relationship between the input features and the target variable\"\n",
        "                      \" by fitting a linear equation to the data. They are simple, interpretable, and provide insights into\"\n",
        "                      \" the contribution of each feature. Ridge Regression and Lasso Regression are variants of Linear Regression\"\n",
        "                      \" that introduce regularization to handle multicollinearity and prevent overfitting. Ridge Regression\"\n",
        "                      \" uses L2 regularization, while Lasso Regression uses L1 regularization. Ridge Regression maintains all\"\n",
        "                      \" features in the model, while Lasso Regression can perform feature selection by shrinking some\"\n",
        "                      \" coefficients to zero.\")\n",
        "                wait_for_user()\n",
        "            elif target_type == '2':\n",
        "                print(\"\\nThe Lasso Regression algorithm is well-suited for regression problems with discrete\"\n",
        "                      \" target variables.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Lasso Regression is a variant of Linear Regression that applies L1 regularization to perform\"\n",
        "                      \" feature selection. It can handle regression problems with discrete target variables by\"\n",
        "                      \" effectively shrinking the coefficients of irrelevant features to zero. Lasso Regression\"\n",
        "                      \" encourages sparsity in the model, making it suitable for feature selection and interpretability.\"\n",
        "                      \" However, Lasso Regression may struggle with high-dimensional data and multicollinearity.\")\n",
        "                wait_for_user()\n",
        "            else:\n",
        "                print(\"Invalid input!\")\n",
        "                wait_for_user()\n",
        "                return\n",
        "\n",
        "        elif problem_complexity == '2':\n",
        "            print(\"\\nBased on your problem type (regression) and problem complexity (moderate),\"\n",
        "                  \" the following algorithms are recommended:\")\n",
        "            print(\"- Decision Trees\")\n",
        "            print(\"- Random Forests\")\n",
        "            print(\"- Gradient Boosting Machines (GBM)\")\n",
        "\n",
        "            print(\"\\nWhat is the nature of your target variable?\")\n",
        "            print(\"1. Continuous\")\n",
        "            print(\"2. Discrete\")\n",
        "            target_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "            if target_type == '1':\n",
        "                print(\"\\nThe Decision Trees, Random Forests, and Gradient Boosting Machines (GBM) algorithms are well-suited for\"\n",
        "                      \" regression problems with continuous target variables.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Decision Trees are hierarchical models that recursively split the feature space based on feature values\"\n",
        "                      \" to make predictions. They are interpretable, handle both numerical and categorical features, and capture\"\n",
        "                      \" non-linear relationships. Random Forests are ensemble learning models that combine multiple decision trees\"\n",
        "                      \" to make predictions. They are robust, handle high-dimensional data, and provide feature importances, making\"\n",
        "                      \" them suitable for regression tasks with moderate complexity. Gradient Boosting Machines (GBM) are also\"\n",
        "                      \" ensemble learning models that sequentially train weak learners to correct the mistakes of previous learners.\"\n",
        "                      \" GBM can handle complex interactions between features and has high predictive power.\")\n",
        "                wait_for_user()\n",
        "            elif target_type == '2':\n",
        "                print(\"\\nThe Decision Trees algorithm is well-suited for regression problems with discrete\"\n",
        "                      \" target variables.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Decision Trees are hierarchical models that recursively split the feature space based on feature values\"\n",
        "                      \" to make predictions. They are interpretable, handle both numerical and categorical features, and capture\"\n",
        "                      \" non-linear relationships. Decision Trees can be used for regression tasks with discrete target variables\"\n",
        "                      \" by predicting the class label associated with the majority of instances in each leaf node.\")\n",
        "                wait_for_user()\n",
        "            else:\n",
        "                print(\"Invalid input!\")\n",
        "                wait_for_user()\n",
        "                return\n",
        "\n",
        "        elif problem_complexity == '3':\n",
        "            print(\"\\nBased on your problem type (regression) and problem complexity (complex),\"\n",
        "                  \" the following algorithms are recommended:\")\n",
        "            print(\"- Deep Learning (e.g., Neural Networks)\")\n",
        "            print(\"- Support Vector Machines (SVM)\")\n",
        "            print(\"- Ensemble Methods (e.g., Stacking, Bagging)\")\n",
        "\n",
        "            print(\"\\nWhat is the nature of your target variable?\")\n",
        "            print(\"1. Continuous\")\n",
        "            print(\"2. Discrete\")\n",
        "            target_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "            if target_type == '1':\n",
        "                print(\"\\nThe Deep Learning (e.g., Neural Networks) and Support Vector Machines (SVM) algorithms are well-suited for\"\n",
        "                      \" regression problems with continuous target variables.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Deep Learning, particularly Neural Networks, is a powerful approach for regression tasks with complex\"\n",
        "                      \" relationships. Neural Networks can capture intricate patterns and learn hierarchical representations of\"\n",
        "                      \" the data. They are highly flexible but require a large amount of labeled data and computational resources\"\n",
        "                      \" for training.\")\n",
        "                print(\"\\nSupport Vector Machines (SVM) are powerful algorithms that find the best hyperplane to approximate the\"\n",
        "                      \" regression function. They can handle both linear and non-linear regression tasks and work well with\"\n",
        "                      \" complex datasets. SVMs can capture complex decision boundaries and are effective in handling high-dimensional\"\n",
        "                      \" data. However, SVMs can be sensitive to the choice of kernel and parameters, and training time can be long\"\n",
        "                      \" for large datasets.\")\n",
        "                wait_for_user()\n",
        "            elif target_type == '2':\n",
        "                print(\"\\nThe Ensemble Methods (e.g., Stacking, Bagging) algorithm is well-suited for regression problems with discrete\"\n",
        "                      \" target variables.\")\n",
        "                print(\"Summary:\")\n",
        "                print(\"Ensemble Methods, such as Stacking and Bagging, combine multiple models to make predictions. They can handle\\n\"\n",
        "                      \" regression tasks with discrete target variables by aggregating the predictions of the individual models.\\n\"\n",
        "                      \" Ensemble Methods can improve the overall predictive performance, reduce overfitting, and provide\\n\"\n",
        "                      \" robustness to the model. However, they may be computationally expensive and require tuning of hyperparameters.\")\n",
        "                wait_for_user()\n",
        "            else:\n",
        "                print(\"Invalid input!\")\n",
        "                wait_for_user()\n",
        "                return\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input!\")\n",
        "            wait_for_user()\n",
        "            return\n",
        "\n",
        "    elif problem_type == '3':\n",
        "        print(\"\\nBased on your problem type (clustering), the following algorithms are recommended:\")\n",
        "        print(\"- k-Means Clustering\")\n",
        "        print(\"- Hierarchical Clustering\")\n",
        "\n",
        "        print(\"\\nWhat is the nature of your data?\")\n",
        "        print(\"1. Numerical\")\n",
        "        print(\"2. Categorical\")\n",
        "        data_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "        if data_type == '1':\n",
        "          print(\"\\nThe k-Means Clustering algorithm is well-suited for clustering problems\"\n",
        "          \" with numerical data.\")\n",
        "          print(\"Summary:\")\n",
        "          print(\"k-Means Clustering is an unsupervised learning algorithm that aims to partition the data into\"\n",
        "          \" 'k' distinct clusters. It is based on the idea of minimizing the within-cluster sum of squares.\"\n",
        "          \" k-Means Clustering works well with numerical data where the clusters can be defined by the\"\n",
        "          \" proximity of data points in the feature space. It is computationally efficient and easy to\"\n",
        "          \" implement. However, it requires the number of clusters 'k' to be predefined and is sensitive\"\n",
        "          \" to the initial choice of cluster centroids.\")\n",
        "          wait_for_user()\n",
        "        elif data_type == '2':\n",
        "          print(\"\\nThe Hierarchical Clustering algorithm is well-suited for clustering problems\"\n",
        "          \" with categorical data.\")\n",
        "          print(\"Summary:\")\n",
        "          print(\"Hierarchical Clustering is an unsupervised learning algorithm that builds a hierarchy of clusters\"\n",
        "          \" by either agglomerative (bottom-up) or divisive (top-down) approaches. It works well with\"\n",
        "          \" categorical data where the clusters can be defined based on similarity or dissimilarity\"\n",
        "          \" measures between data points. Hierarchical Clustering does not require the number of clusters\"\n",
        "          \" to be predefined and can handle datasets with varying cluster sizes. However, it can be\"\n",
        "          \" computationally expensive for large datasets.\")\n",
        "          wait_for_user()\n",
        "        else:\n",
        "          print(\"Invalid input!\")\n",
        "          wait_for_user()\n",
        "          return\n",
        "\n",
        "    elif problem_type == '4':\n",
        "        print(\"\\nBased on your problem type (dimension analysis), the following algorithms are recommended:\")\n",
        "        print(\"- Principal Component Analysis (PCA)\")\n",
        "        print(\"- t-SNE (t-Distributed Stochastic Neighbor Embedding)\")\n",
        "        print(\"- UMAP (Uniform Manifold Approximation and Projection)\")\n",
        "\n",
        "        print(\"\\nWhat is the nature of your data?\")\n",
        "        print(\"1. Numerical\")\n",
        "        print(\"2. Categorical\")\n",
        "        data_type = input(\"Enter the corresponding number: \")\n",
        "\n",
        "        if data_type == '1':\n",
        "          print(\"\\nThe Principal Component Analysis (PCA) algorithm is well-suited for dimension analysis\"\n",
        "          \" with numerical data.\")\n",
        "          print(\"Summary:\")\n",
        "          print(\"Principal Component Analysis (PCA) is a dimensionality reduction technique that aims to\"\n",
        "          \" transform high-dimensional data into a lower-dimensional space while retaining most of the\"\n",
        "          \" data variance. It achieves this by finding the principal components that capture the maximum\"\n",
        "          \" amount of variation in the data. PCA is particularly useful for reducing the dimensionality of\"\n",
        "          \" numerical data and visualizing high-dimensional datasets. However, PCA assumes linear\"\n",
        "          \" relationships between variables and may not perform well on nonlinear datasets.\")\n",
        "          wait_for_user()\n",
        "        elif data_type == '2':\n",
        "          print(\"\\nThe t-SNE (t-Distributed Stochastic Neighbor Embedding) and UMAP (Uniform Manifold\"\n",
        "          \" Approximation and Projection) algorithms are well-suited for dimension analysis with\"\n",
        "          \" categorical data.\")\n",
        "          print(\"Summary (t-SNE):\")\n",
        "          print(\"t-SNE is a nonlinear dimensionality reduction technique that aims to preserve the local\"\n",
        "         \" structure of the data in the low-dimensional space. It is particularly effective at\"\n",
        "          \" visualizing high-dimensional categorical data by revealing clusters and patterns that may\"\n",
        "          \" be difficult to discern in the original space. However, t-SNE can be computationally\"\n",
        "          \" expensive for large datasets.\")\n",
        "\n",
        "          print(\"Summary (UMAP):\")\n",
        "          print(\"UMAP is a nonlinear dimensionality reduction technique that uses manifold learning\"\n",
        "          \" algorithms to preserve the global structure of the data in the low-dimensional space. It\"\n",
        "          \" is known for its scalability and ability to capture complex patterns in high-dimensional\"\n",
        "          \" categorical data. UMAP provides a flexible framework for exploring and visualizing\"\n",
        "          \" high-dimensional datasets. However, UMAP may require parameter tuning for optimal results.\")\n",
        "          wait_for_user()\n",
        "        else:\n",
        "          print(\"Invalid input!\")\n",
        "          wait_for_user()\n",
        "        return\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid input!\")\n",
        "        wait_for_user()\n",
        "        return\n",
        "\n",
        "    print(\"\\nThank you for using the Machine Learning Algorithm Suggestion Program!\")\n",
        "    wait_for_user()\n",
        "\n",
        "suggest_ml_models()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgvsG1U40boc",
        "outputId": "21ce6a30-9f77-44f3-c204-f0c38ec25f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Machine Learning Algorithm Suggestion Program!\n",
            "Answer a few questions to find the most suitable ML algorithm for your problem.\n",
            "\n",
            "What is the nature of your problem?\n",
            "1. Classification\n",
            "2. Regression\n",
            "3. Clustering\n",
            "4. Dimension Analysis\n",
            "Enter the corresponding number: 3\n",
            "\n",
            "Based on your problem type (clustering), the following algorithms are recommended:\n",
            "- k-Means Clustering\n",
            "- Hierarchical Clustering\n",
            "\n",
            "What is the nature of your data?\n",
            "1. Numerical\n",
            "2. Categorical\n",
            "Enter the corresponding number: 1\n",
            "\n",
            "The k-Means Clustering algorithm is well-suited for clustering problems with numerical data.\n",
            "Summary:\n",
            "k-Means Clustering is an unsupervised learning algorithm that aims to partition the data into 'k' distinct clusters. It is based on the idea of minimizing the within-cluster sum of squares. k-Means Clustering works well with numerical data where the clusters can be defined by the proximity of data points in the feature space. It is computationally efficient and easy to implement. However, it requires the number of clusters 'k' to be predefined and is sensitive to the initial choice of cluster centroids.\n",
            "\n",
            "Press Enter to continue...\n",
            "\n",
            "Thank you for using the Machine Learning Algorithm Suggestion Program!\n"
          ]
        }
      ]
    }
  ]
}